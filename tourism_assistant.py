from enum import Enum
from typing import Dict, Any, Generator, List
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableSequence
from langchain.prompts import PromptTemplate
from langchain_nvidia_ai_endpoints import ChatNVIDIA
import re
import time
import os
import json

NVIDIA_API_KEY = "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"

# ---------- çŠ¶æ€æšä¸¾ä¿®æ­£ ----------
class TourismState(Enum):
    INIT = "åˆå§‹åŒ–"
    GET_PREFERENCE = "è·å–åå¥½"
    SELECT_SPOT = "é€‰æ‹©æ™¯ç‚¹"
    SELECT_ROUTE = "é€‰æ‹©è·¯çº¿"


# ---------- å¤„ç†é“¾æ„å»º ----------
def build_processing_chain(prompt: PromptTemplate) -> RunnableSequence:
    """ä¿®æ­£åçš„å¤„ç†é“¾"""
    llm = create_llm()
    return (
        RunnablePassthrough()
        | prompt
        | llm  # ç§»é™¤äº†.streamç›´æ¥è°ƒç”¨
        | RunnableLambda(lambda chunk: chunk.content)  # æå–contentå­—æ®µ
    )

# ---------- å“åº”ç”Ÿæˆ ----------
def format_streaming_response(content: str, options: list = None) -> Generator[Dict[str, Any], None, None]:
    """ä¿®æ­£åçš„æµå¼å“åº”ç”Ÿæˆå™¨"""
    # æŒ‰è‡ªç„¶è¯­ä¹‰åˆ†å‰²ï¼ˆæ ‡ç‚¹ç»“å°¾ä¸ºåˆ†å‰²ç‚¹ï¼‰
    segments = re.findall(r'.+?[ã€‚ï¼ï¼Ÿ\n]|.+?(?=\s|$)', content)
    
    for seg in segments:
        yield {
            "messages": [{
                "role": "assistant",
                "content": seg.strip()  # æ¯æ¬¡è¿”å›å¢é‡å†…å®¹
            }],
            "options": options or []
        }
        time.sleep(0.2)  # è°ƒæ•´åˆ°æ›´è‡ªç„¶çš„è¯­é€Ÿ

# ---------- Markdownæ¸²æŸ“ ----------
def render_markdown(content: str) -> str:
    """å®‰å…¨æ¸²æŸ“Markdownå†…å®¹"""
    sanitized = re.sub(r'[^\w\s\-\.\!\?\u4e00-\u9fa5]', '', content)
    return f"```markdown\n{sanitized}\n```"

# ---------- æ ¸å¿ƒå‡½æ•°é‡æ„ ----------
def create_llm():
    """åˆ›å»ºLLMå®ä¾‹"""
    return ChatNVIDIA(
        model="meta/llama-3.3-70b-instruct",
        temperature=0.2,
        top_p=0.7,
        max_tokens=1024,
        nvidia_api_key=NVIDIA_API_KEY
    )

def state_machine(state: Dict, user_input: str) -> Generator[Dict, None, None]:
    """å¢å¼ºå‹çŠ¶æ€æœº"""
    current_state = {
        "step": state.get("step", TourismState.INIT),
        "preference": state.get("preference"),
        "selected_spot": state.get("selected_spot"),
        "selected_route": state.get("selected_route"),
        "options": state.get("options", []),
        "context": state.get("context", {})  # æ–°å¢ä¸Šä¸‹æ–‡å­˜å‚¨
    }
    handlers = {
        TourismState.INIT: handle_init,
        TourismState.GET_PREFERENCE: handle_preference,
        TourismState.SELECT_SPOT: handle_spot_selection,
        TourismState.SELECT_ROUTE: handle_route_selection
    }
    
    handler = handlers.get(current_state["step"], handle_unknown)
    response_gen = handler(current_state, user_input)
    
    try:
        while True:
            chunk = next(response_gen)
            yield chunk
    except StopIteration as e:
        # ä¿®æ­£è¿”å›å€¼å¤„ç†
        new_state = e.value if isinstance(e.value, dict) else current_state
        yield {"messages": [{"role": "assistant", "content": ""}], "final_state": new_state}

# ---------- çŠ¶æ€å¤„ç†å‡½æ•°é‡æ„ ----------
def handle_init(state: Dict, _: str) -> Generator[Dict, None, Dict]:
    """åˆå§‹åŒ–å¤„ç†"""
    full_response = "ğŸ–ï¸ è¯·é—®æ‚¨æƒ³è¦ä»€ä¹ˆæ ·çš„æ—…æ¸¸ä½“éªŒå‘¢ï¼Ÿ"
    yield from format_streaming_response(full_response)
    # æ˜ç¡®è¿”å›æ›´æ–°åçš„çŠ¶æ€
    return {
        **state,
        "step": TourismState.GET_PREFERENCE,
        "preference": None,
        "selected_spot": None,
        "selected_route": None
    }

# æ–°å¢è§£ææç¤ºæ¨¡æ¿
OPTION_PROMPTS = {
    "spot": PromptTemplate(
        input_variables=["content"],
        template="""ä»å¯¼æ¸¸å›å¤ä¸­æå–æ™¯ç‚¹åç§°åˆ—è¡¨ï¼š
{content}

è¦æ±‚ï¼š
1. åªè¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«spotså­—æ®µçš„æ•°ç»„
2. ä»…åŒ…å«æ™¯ç‚¹åç§°ï¼Œä¸è¦æè¿°
3. ç¤ºä¾‹ï¼š["æ™¯ç‚¹1", "æ™¯ç‚¹2", "æ™¯ç‚¹3"]"""
    ),
    "route": PromptTemplate(
        input_variables=["content"],
        template="""ä»è·¯çº¿æ¨èä¸­æå–è·¯çº¿åç§°ï¼š
{content}

è¦æ±‚ï¼š
1. åªè¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«routeså­—æ®µçš„æ•°ç»„  
2. åç§°éœ€å®Œæ•´åŒ…å«è·¯çº¿ç‰¹è‰²
3. ç¤ºä¾‹ï¼š["è·¯çº¿1", "è·¯çº¿2", "è·¯çº¿3"]"""
    )
}

# ç‹¬ç«‹çš„å°æ¨¡å‹è§£æå™¨
option_parser_llm = ChatNVIDIA(
    model="meta/llama3-8b-instruct",
    temperature=0.1,
    top_p=0.9,
    max_tokens=512,
    nvidia_api_key=NVIDIA_API_KEY
)

# ä¸“ç”¨è§£æé“¾
option_parser = {
    "spot": OPTION_PROMPTS["spot"] | option_parser_llm | StrOutputParser() | json.loads,
    "route": OPTION_PROMPTS["route"] | option_parser_llm | StrOutputParser() | json.loads
}

# ä¿®æ”¹è§£æå‡½æ•°
def parse_options(content: str, option_type: str) -> List[str]:
    """ä½¿ç”¨ä¸“ç”¨æç¤ºè§£æé€‰é¡¹"""
    try:
        return option_parser[option_type].invoke({"content": content})[f"{option_type}s"]
    except Exception as e:
        print(f"âš ï¸ è§£æå¤±è´¥ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼š{str(e)}")
        # å¢å¼ºå‹æ­£åˆ™åŒ¹é…
        patterns = {
            "spot": r"\d+\.\s+\*\*(.*?)\*\*",
            "route": r"\d+\.\s+\*\*(.*?)\*\*|\d+\.\s+\[(.*?)\]"
        }
        return re.findall(patterns[option_type], content)

def handle_preference(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆæ™¯ç‚¹æ¨èï¼ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆï¼‰"""
    # ä»çŸ¥è¯†åº“è·å–ä¸Šä¸‹æ–‡ï¼ˆç¤ºä¾‹ï¼‰
    context = {
        "spots": ["æ•…å®«", "é¢å’Œå›­", "å¤©å›", "åœ†æ˜å›­"],
        "history": "åŒ—äº¬ä¸»è¦çš‡å®¶æ™¯ç‚¹"
    }
    
    chain = build_processing_chain(SPOT_PROMPT)
    result = chain.invoke({
        "context": context,  # åŠ¨æ€ä¸Šä¸‹æ–‡
        "preference": user_input
    })
    
    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(result)
    
    # æ›´æ–°ä¸Šä¸‹æ–‡
    new_context = {
        **context,
        "preference_details": user_input,
        "generated_at": time.strftime("%Y-%m-%d %H:%M")
    }
    
    return {
        **state,
        "step": TourismState.SELECT_SPOT,
        "preference": user_input,
        "options": parse_options(result, "spot"),
        "context": new_context  # ä¼ é€’ä¸Šä¸‹æ–‡
    }

def handle_spot_selection(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆè·¯çº¿æ¨èï¼ˆå¢å¼ºç‰ˆï¼‰"""
    chain = build_processing_chain(ROUTE_PROMPT)
    result = chain.invoke({"preference": state["preference"], "spot": "é¢å’Œå›­"})
    
    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(result)
    
    # ä½¿ç”¨å°æ¨¡å‹è§£æè·¯çº¿é€‰é¡¹
    try:
        options = parse_options(result, "route")
    except Exception:
        options = re.findall(r"\d+\.\s+\[(.*?)\]", result)
    
    return {
        **state, 
        "step": TourismState.SELECT_ROUTE,
        "selected_spot": "é¢å’Œå›­",
        "options": options
    }

def handle_route_selection(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆæ”»ç•¥ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    chain = build_processing_chain(GUIDE_PROMPT)
    result = chain.invoke({
        "preference": state["preference"],
        "spot": state["selected_spot"],
        "route": "è¥¿å ¤æ¼«æ­¥çº¿"
    })
    
    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(render_markdown(result))
    return {
        **state,
        "step": TourismState.INIT,
        "selected_route": "è¥¿å ¤æ¼«æ­¥çº¿"
    }

def handle_unknown(state: Dict, _: str) -> Generator[Dict, None, None]:
    """æœªçŸ¥çŠ¶æ€å¤„ç†"""
    yield from format_streaming_response("âš ï¸ ç³»ç»Ÿé‡åˆ°æœªçŸ¥çŠ¶æ€ï¼Œæ­£åœ¨é‡ç½®...")
    return {**state, "step": TourismState.INIT}

# ---------- å®Œæ•´æç¤ºæ¨¡æ¿ ----------
SPOT_PROMPT = PromptTemplate(
    input_variables=["context", "preference"],
    template="""ä½œä¸ºèµ„æ·±æ—…è¡Œè§„åˆ’å¸ˆï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨è3ä¸ªæ™¯ç‚¹ï¼š
    
å†å²èƒŒæ™¯ï¼š{context}
ç”¨æˆ·éœ€æ±‚ï¼š{preference}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ¨èï¼š
1. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]
2. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]
3. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]"""
)

ROUTE_PROMPT = PromptTemplate(
    input_variables=["preference", "spot"],
    template="""ç”¨æˆ·åå¥½ï¼š{preference}
é€‰å®šæ™¯ç‚¹ï¼š{spot}

è¯·è®¾è®¡3ç§ç‰¹è‰²æ¸¸è§ˆè·¯çº¿ï¼š
1. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]
2. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]
3. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]"""
)

GUIDE_PROMPT = PromptTemplate(
    input_variables=["preference", "spot", "route"],
    template="""# æ·±åº¦æ—…æ¸¸æ”»ç•¥ç”Ÿæˆ
    
ç”¨æˆ·éœ€æ±‚ï¼š{preference}
é€‰å®šæ™¯ç‚¹ï¼š{spot}
é€‰æ‹©è·¯çº¿ï¼š{route}

è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
## è¡Œç¨‹å®‰æ’ï¼ˆç²¾ç¡®åˆ°å°æ—¶ï¼‰
## å¿…ç©é¡¹ç›®
## é¤é¥®æ¨è
## é¢„ç®—ä¼°ç®—
## å®ç”¨è´´å£«"""
)

def test_llm_connection():
    """å¤§æ¨¡å‹è¿é€šæ€§æµ‹è¯•"""
    print("\n=== å¼€å§‹å¤§æ¨¡å‹è¿é€šæ€§æµ‹è¯• ===")
    try:
        llm = create_llm()
        test_prompt = PromptTemplate.from_template("è¯·è¯´ï¼š'æµ‹è¯•æˆåŠŸ'")
        chain = test_prompt | llm
        
        # å¸¦è¶…æ—¶çš„æµ‹è¯•è¯·æ±‚
        response = chain.invoke({"dummy": ""}).content
        if "æµ‹è¯•æˆåŠŸ" in response:
            print(f"âœ… å¤§æ¨¡å‹è¿æ¥æˆåŠŸï¼å“åº”å†…å®¹ï¼š{response}")
            return True
        else:
            print(f"âš ï¸ å¼‚å¸¸å“åº”ï¼š{response}")
            return False
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥ï¼š{str(e)}")
        print("å¯èƒ½åŸå› ï¼š")
        print("1. APIå¯†é’¥æ— æ•ˆ")
        print("2. ç½‘ç»œè¿æ¥å¼‚å¸¸")
        print("3. æ¨¡å‹æœåŠ¡ä¸å¯ç”¨")
        return False

# ---------- æ–°å¢æµ‹è¯•éªŒè¯å‡½æ•° ----------
def test_initialization() -> Dict:
    """æµ‹è¯•åˆå§‹åŒ–æµç¨‹"""
    print("\n=== æµ‹è¯•åˆå§‹åŒ– ===")
    state = {"step": TourismState.INIT}
    response_gen = state_machine(state, "")
    
    full_response = ""
    final_state = state
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                final_state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration:
        pass
    
    # éªŒè¯å…³é”®å­—æ®µ
    assert final_state["step"] == TourismState.GET_PREFERENCE, "åˆå§‹åŒ–ååº”è¿›å…¥åå¥½è·å–çŠ¶æ€"
    print("âœ… åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    return final_state

def test_preference_input(prev_state: Dict) -> Dict:
    """æµ‹è¯•åå¥½è¾“å…¥æµç¨‹"""
    print("\n=== æµ‹è¯•åå¥½è¾“å…¥ ===")
    user_input = "æˆ‘æƒ³çœ‹çš‡å®¶å›­æ—"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state  # åˆå§‹åŒ–çŠ¶æ€
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    # éªŒè¯é€‰é¡¹ç”Ÿæˆ
    assert len(state["options"]) >= 1, "åº”ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ™¯ç‚¹é€‰é¡¹"
    assert state["step"] == TourismState.SELECT_SPOT, "è¾“å…¥åå¥½ååº”è¿›å…¥æ™¯ç‚¹é€‰æ‹©çŠ¶æ€"
    print("âœ… åå¥½è¾“å…¥æµ‹è¯•é€šè¿‡")
    return state

def test_spot_selection(prev_state: Dict) -> Dict:
    """æµ‹è¯•æ™¯ç‚¹é€‰æ‹©æµç¨‹"""
    print("\n=== æµ‹è¯•æ™¯ç‚¹é€‰æ‹© ===")
    user_input = "é€‰ç¬¬ä¸€ä¸ªæ™¯ç‚¹"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    assert "selected_spot" in state, "åº”è®°å½•å·²é€‰æ™¯ç‚¹"
    assert len(state["options"]) >= 1, "åº”ç”Ÿæˆè‡³å°‘ä¸€ä¸ªè·¯çº¿é€‰é¡¹"
    print("âœ… æ™¯ç‚¹é€‰æ‹©æµ‹è¯•é€šè¿‡")
    return state

def test_route_selection(prev_state: Dict) -> Dict:
    """æµ‹è¯•è·¯çº¿é€‰æ‹©æµç¨‹"""
    print("\n=== æµ‹è¯•è·¯çº¿é€‰æ‹© ===")
    user_input = "é€‰æ–‡åŒ–è·¯çº¿"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state  # å…³é”®ä¿®å¤ï¼šåˆå§‹åŒ–çŠ¶æ€
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    # éªŒè¯æœ€ç»ˆçŠ¶æ€
    assert state["step"] == TourismState.INIT, "å®Œæˆæµç¨‹ååº”é‡ç½®çŠ¶æ€"
    assert "selected_route" in state, "åº”è®°å½•å·²é€‰è·¯çº¿"
    print("âœ… è·¯çº¿é€‰æ‹©æµ‹è¯•é€šè¿‡")
    return state

# æ–°å¢äº¤äº’æ¼”ç¤ºå‡½æ•°
def interactive_demo():
    """å‘½ä»¤è¡Œäº¤äº’æ¼”ç¤º"""
    print("ğŸ›« æ—…æ¸¸åŠ©æ‰‹ äº¤äº’æ¨¡å¼ï¼ˆè¾“å…¥exité€€å‡ºï¼‰")
    state = {"step": TourismState.INIT}
    
    while True:
        try:
            # æ ¹æ®çŠ¶æ€æç¤ºè¾“å…¥
            if state["step"] == TourismState.INIT:
                user_input = input("\n> æŒ‰å›è½¦å¼€å§‹è§„åˆ’æ—…ç¨‹ï¼š") or ""
            elif state["step"] == TourismState.GET_PREFERENCE:
                user_input = input("\n> è¯·æè¿°æ‚¨çš„æ—…æ¸¸åå¥½ï¼ˆå¦‚ï¼šæƒ³çœ‹çš‡å®¶å»ºç­‘ï¼‰ï¼š")
            elif state["step"] == TourismState.SELECT_SPOT:
                print("\næ¨èæ™¯ç‚¹ï¼š")
                for i, spot in enumerate(state["options"], 1):
                    print(f"  {i}. {spot}")
                user_input = input("> è¯·é€‰æ‹©æ™¯ç‚¹ç¼–å·æˆ–åç§°ï¼š")
            elif state["step"] == TourismState.SELECT_ROUTE:
                print("\næ¨èè·¯çº¿ï¼š")
                for i, route in enumerate(state["options"], 1):
                    print(f"  {i}. {route}")
                user_input = input("> è¯·é€‰æ‹©è·¯çº¿ç¼–å·æˆ–åç§°ï¼š")
            
            if user_input.lower() == "exit":
                break

            # å¤„ç†è¾“å…¥
            full_response = ""
            response_gen = state_machine(state, user_input)
            for chunk in response_gen:
                if chunk.get("final_state"):
                    state = chunk["final_state"]
                    continue
                content = chunk['messages'][0]['content']
                print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
                full_response += content
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            if state["step"] == TourismState.INIT and "selected_route" in state:
                print("\n\nâœ… è¡Œç¨‹è§„åˆ’å®Œæˆï¼")
                print("-"*50)
                print(full_response)
                print("-"*50)
                state = {"step": TourismState.INIT}  # é‡ç½®çŠ¶æ€

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break

# ---------- æ›´æ–°ä¸»æµç¨‹ ----------
if __name__ == "__main__":
    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = create_llm()
    print("âœ… å¤§æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    
    # å¯åŠ¨äº¤äº’æ¨¡å¼
    interactive_demo()

