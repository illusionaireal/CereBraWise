from enum import Enum
from typing import Dict, Any, Generator, List
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableSequence, RunnableBranch, RunnableAssign
from langchain.prompts import PromptTemplate
from langchain_nvidia_ai_endpoints import ChatNVIDIA
import re
import time
import os
import json

NVIDIA_API_KEY = "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"

# ---------- çŠ¶æ€æšä¸¾ä¿®æ­£ ----------
class TourismState(Enum):
    INIT = "åˆå§‹åŒ–"
    GET_PREFERENCE = "è·å–åå¥½"
    SELECT_SPOT = "é€‰æ‹©æ™¯ç‚¹"
    SELECT_ROUTE = "é€‰æ‹©è·¯çº¿"


# ---------- å¤„ç†é“¾ ç¤ºä¾‹ä»£ç  ----------
def build_processing_chain(prompt: PromptTemplate) -> RunnableSequence:
    """å¤„ç†é“¾æ¨¡ç‰ˆ"""
    llm = create_llm()
    return (
        RunnablePassthrough()
        | prompt
        | llm  # ç§»é™¤äº†.streamç›´æ¥è°ƒç”¨
        | RunnableLambda(lambda chunk: chunk.content)  # æå–contentå­—æ®µ
    )

# ---------- å“åº”ç”Ÿæˆ ----------
def format_streaming_response(content: str, options: list = None) -> Generator[Dict[str, Any], None, None]:
    """ä¿®æ­£åçš„æµå¼å“åº”ç”Ÿæˆå™¨"""
    # æŒ‰è‡ªç„¶è¯­ä¹‰åˆ†å‰²ï¼ˆæ ‡ç‚¹ç»“å°¾ä¸ºåˆ†å‰²ç‚¹ï¼‰
    segments = re.findall(r'.+?[ã€‚ï¼ï¼Ÿ\n]|.+?(?=\s|$)', content)
    
    for seg in segments:
        yield {
            "messages": [{
                "role": "assistant",
                "content": seg.strip()  # æ¯æ¬¡è¿”å›å¢é‡å†…å®¹
            }],
            "options": options or []
        }
        time.sleep(0.2)  # è°ƒæ•´åˆ°æ›´è‡ªç„¶çš„è¯­é€Ÿ

# ---------- Markdownæ¸²æŸ“ æœªå®è£…----------
def render_markdown(content: str) -> str:
    """å®‰å…¨æ¸²æŸ“Markdownå†…å®¹"""
    sanitized = re.sub(r'[^\w\s\-\.\!\?\u4e00-\u9fa5]', '', content)
    return f"```markdown\n{sanitized}\n```"

def create_llm():
    """åˆ›å»ºLLMå®ä¾‹"""
    # NIMæ¨¡ç‰ˆä»£ç 
    return ChatNVIDIA(
        model="meta/llama-3.3-70b-instruct",
        temperature=0.2,
        top_p=0.7,
        max_tokens=1024,
        nvidia_api_key=NVIDIA_API_KEY
    )

# ---------- æ–°å¢é“¾å¼çŠ¶æ€å¤„ç† ----------
def build_state_chain() -> RunnableBranch:
    """æ„å»ºé“¾å¼çŠ¶æ€å¤„ç†å™¨"""
    return RunnableBranch(
        # INITçŠ¶æ€å¤„ç†
        (lambda s: s["step"] == TourismState.INIT, 
         RunnableAssign({
             "messages": RunnableLambda(handle_init) | format_streaming_response,
             "step": lambda _: TourismState.GET_PREFERENCE
         })),
         
        # GET_PREFERENCEçŠ¶æ€å¤„ç†
        (lambda s: s["step"] == TourismState.GET_PREFERENCE,
         RunnableAssign({
             "messages": RunnableLambda(handle_preference) | format_streaming_response,
             "options": RunnableLambda(lambda s: parse_options(s["messages"], "spot")),
             "step": lambda _: TourismState.SELECT_SPOT
         })),
         
        # SELECT_SPOTçŠ¶æ€å¤„ç† 
        (lambda s: s["step"] == TourismState.SELECT_SPOT,
         RunnableAssign({
             "messages": RunnableLambda(handle_spot_selection) | format_streaming_response,
             "options": RunnableLambda(lambda s: parse_options(s["messages"], "route")),
             "step": lambda _: TourismState.SELECT_ROUTE
         })),
         
        # æ–°å¢SELECT_ROUTEçŠ¶æ€å¤„ç†
        (lambda s: s["step"] == TourismState.SELECT_ROUTE,
         RunnableAssign({
             "messages": RunnableLambda(handle_route_selection) | format_streaming_response,
             "step": lambda _: TourismState.INIT
         })),
         
        # é»˜è®¤å¤„ç† (æ·»åŠ Trueä½œä¸ºé»˜è®¤æ¡ä»¶)
        (True,
         RunnableAssign({
             "messages": RunnableLambda(handle_unknown) | format_streaming_response,
             "step": lambda _: TourismState.INIT
         }))
    )


# ---------- æ›´æ–°çŠ¶æ€æœºå‡½æ•° ----------
def state_machine(state: Dict, user_input: str) -> Generator[Dict, None, None]:
    """å¢å¼ºå‹çŠ¶æ€æœº"""
    current_state = {
        "step": state.get("step", TourismState.INIT),
        "preference": state.get("preference"),
        "selected_spot": state.get("selected_spot"),
        "selected_route": state.get("selected_route"),
        "options": state.get("options", []),
        "context": state.get("context", {})  # æ–°å¢ä¸Šä¸‹æ–‡å­˜å‚¨
    }
    handlers = {
        TourismState.INIT: handle_init,
        TourismState.GET_PREFERENCE: handle_preference,
        TourismState.SELECT_SPOT: handle_spot_selection,
        TourismState.SELECT_ROUTE: handle_route_selection
    }
    
    handler = handlers.get(current_state["step"], handle_unknown)
    response_gen = handler(current_state, user_input)
    
    try:
        while True:
            chunk = next(response_gen)
            yield chunk
    except StopIteration as e:
        # ä¿®æ­£è¿”å›å€¼å¤„ç†
        new_state = e.value if isinstance(e.value, dict) else current_state
        yield {"messages": [{"role": "assistant", "content": ""}], "final_state": new_state}

# ---------- çŠ¶æ€å¤„ç†å‡½æ•°é‡æ„ ----------
def handle_init(state: Dict, _: str) -> Generator[Dict, None, Dict]:
    """åˆå§‹åŒ–å¤„ç†"""
    full_response = "ğŸ–ï¸ è¯·é—®æ‚¨æƒ³è¦ä»€ä¹ˆæ ·çš„æ—…æ¸¸ä½“éªŒå‘¢ï¼Ÿ"
    yield from format_streaming_response(full_response)
    # æ˜ç¡®è¿”å›æ›´æ–°åçš„çŠ¶æ€
    return {
        **state,
        "step": TourismState.GET_PREFERENCE,
        "preference": None,
        "selected_spot": None,
        "selected_route": None
    }

# æ–°å¢è§£ææç¤ºæ¨¡æ¿
OPTION_PROMPTS = {
    "spot": PromptTemplate(
        input_variables=["content"],
        template="""ä»å¯¼æ¸¸å›å¤ä¸­æå–æ™¯ç‚¹åç§°åˆ—è¡¨ï¼š
{content}

è¦æ±‚ï¼š
1. åªè¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«spotså­—æ®µçš„æ•°ç»„
2. åŒ…å«æ™¯ç‚¹åç§°å’Œæè¿°
3. ç¤ºä¾‹ï¼š["æ™¯ç‚¹1ï¼šæ™¯ç‚¹1æè¿°", "æ™¯ç‚¹2ï¼šæ™¯ç‚¹2æè¿°", "æ™¯ç‚¹3ï¼šæ™¯ç‚¹3æè¿°"]"""
    ),
    "route": PromptTemplate(
        input_variables=["content"],
        template="""ä»è·¯çº¿æ¨èä¸­æå–è·¯çº¿åç§°ï¼š
{content}

è¦æ±‚ï¼š
1. åªè¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«routeså­—æ®µçš„æ•°ç»„  
2. åŒ…å«å®Œæ•´åç§°å’Œè·¯çº¿ç‰¹è‰²
3. ç¤ºä¾‹ï¼š["è·¯çº¿1ï¼šè·¯çº¿ç‰¹è‰²", "è·¯çº¿2ï¼šè·¯çº¿ç‰¹è‰²", "è·¯çº¿3ï¼šè·¯çº¿ç‰¹è‰²"]"""
    )
}

# ç‹¬ç«‹çš„å°æ¨¡å‹è§£æå™¨
option_parser_llm = ChatNVIDIA(
    model="meta/llama3-8b-instruct",
    temperature=0.1,
    top_p=0.9,
    max_tokens=512,
    nvidia_api_key=NVIDIA_API_KEY
)

# ä¸“ç”¨è§£æé“¾
option_parser = {
    "spot": OPTION_PROMPTS["spot"] | option_parser_llm | StrOutputParser() | json.loads,
    "route": OPTION_PROMPTS["route"] | option_parser_llm | StrOutputParser() | json.loads
}

# ä¿®æ”¹è§£æå‡½æ•°
def parse_options(content: str, option_type: str) -> List[str]:
    """ä½¿ç”¨ä¸“ç”¨æç¤ºè§£æé€‰é¡¹"""
    try:
        return option_parser[option_type].invoke({"content": content})[f"{option_type}s"]
    except Exception as e:
        print(f"âš ï¸ è§£æå¤±è´¥ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼š{str(e)}")
        # å¢å¼ºå‹æ­£åˆ™åŒ¹é…
        patterns = {
            "spot": r"\d+\.\s+\*\*(.*?)\*\*",
            "route": r"\d+\.\s+\*\*(.*?)\*\*|\d+\.\s+\[(.*?)\]"
        }
        return re.findall(patterns[option_type], content)
        

def get_rag_multi_model_context(query:str)->str:
    '''æ ¹æ®ç”¨æˆ·è¾“å…¥ä½¿ç”¨RAGå¤šæ¨¡æ€å¾—åˆ°ä¿¡æ¯'''
    # æš‚æ—¶ç›´æ¥è¿”å›ï¼Œå¾…ç®—æ³•ç»„ç»“æœã€‚

    return query

def handle_preference_chain() -> RunnableSequence:
    """ä¸“ç”¨åå¥½å¤„ç†é“¾"""
    llm = create_llm()
    spot_prompt = PromptTemplate(
        input_variables=["preference_info"],  # ç¡®ä¿è¾“å…¥å˜é‡åŒ¹é…
        template="""ä½œä¸ºèµ„æ·±æ—…è¡Œè§„åˆ’å¸ˆï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨è3ä¸ªæ™¯ç‚¹ï¼š
        
    ç”¨æˆ·éœ€æ±‚ï¼š{preference_info}

    è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ¨èï¼š
    1. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]
    2. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]
    3. [æ™¯ç‚¹åç§°]ï¼š[50å­—ç‰¹è‰²æè¿°]"""
    )
    return (
        RunnablePassthrough()
        | spot_prompt 
        | llm.bind(stop=["\n\n"])
        | RunnableLambda(lambda x: x.content)
    )

def handle_preference(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆæ™¯ç‚¹æ¨èï¼ˆçŸ¥è¯†åº“å¢å¼ºç‰ˆï¼‰"""
    # ä»çŸ¥è¯†åº“åŠ¨æ€è·å–ä¸Šä¸‹æ–‡
    preference = get_rag_multi_model_context(user_input)  # RAGå¤šæ¨¡æ€è§£æ
    
    # æ­£ç¡®åˆå§‹åŒ–å¤„ç†é“¾
    chain = handle_preference_chain()  
    result = chain.invoke({"preference_info": preference})  # å‚æ•°åœ¨æ­¤å¤„ä¼ é€’
    
    # ç±»å‹å®‰å…¨æ£€æŸ¥
    if not isinstance(result, str):
        result = str(result)
    
    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(result)
    
    return {
        **state,
        "step": TourismState.SELECT_SPOT,
        "options": parse_options(result, "spot"),
        "context": {
            "preference_info": preference,
            "timestamp": time.strftime("%Y-%m-%d %H:%M")
        }
    }

def spot_selection_parse(user_input: str, options: list, context: dict) -> str:
    """ä½¿ç”¨å°æ¨¡å‹è§£ææ™¯ç‚¹é€‰æ‹©"""
    prompt = PromptTemplate(
        template="ä»ç”¨æˆ·è¾“å…¥ä¸­è§£ææ™¯ç‚¹é€‰æ‹©ï¼š\né€‰é¡¹åˆ—è¡¨ï¼š{options}\nç”¨æˆ·è¾“å…¥ï¼š{user_input}\nè¿”å›[æ™¯ç‚¹åç§°ï¼šç‰¹è‰²æè¿°]",
        input_variables=["options", "user_input"]
    )
    chain = prompt | option_parser_llm | StrOutputParser()
    return chain.invoke({"options": options, "user_input": user_input})

def handle_spot_selection_chain() -> RunnableSequence:
    """ä¸“ç”¨æ™¯ç‚¹å¤„ç†é“¾"""
    llm = create_llm()
    route_prompt = PromptTemplate(
        input_variables=["preference_info", "spot_info"],
        template="""ä½œä¸ºèµ„æ·±æ—…è¡Œè§„åˆ’å¸ˆï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œé€‰å®šæ™¯ç‚¹è®¾è®¡3æ¡ç‰¹è‰²æ—…æ¸¸è·¯çº¿:
    ç”¨æˆ·åå¥½ï¼š{preference_info}
    é€‰å®šæ™¯ç‚¹ï¼š{spot_info}

    è¯·è®¾è®¡3æ¡ç‰¹è‰²æ¸¸è§ˆè·¯çº¿ï¼š
    1. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]
    2. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]
    3. [è·¯çº¿åç§°]ï¼š[è·¯çº¿ç‰¹è‰²ä¸äº®ç‚¹]"""
    )
    return (
        RunnablePassthrough()
        | route_prompt
        | llm
        | StrOutputParser()
    )

def handle_spot_selection(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆè·¯çº¿æ¨èï¼ˆå¢å¼ºç‰ˆï¼‰"""
    selected_spot = spot_selection_parse(
        user_input, 
        state["options"],
        context=state["context"]
    )


    result = handle_spot_selection_chain().invoke({
        "preference_info": state["context"]["preference_info"],
        "spot_info": selected_spot
    })

    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(result)
    
    return {
        **state,
        "step": TourismState.SELECT_ROUTE,
        "options": parse_options(result, "route"),
        "context": {
            "preference_info": state["context"]["preference_info"],
            "spot_info": selected_spot,
            "timestamp": time.strftime("%Y-%m-%d %H:%M")
        }
    }

def route_selection_parse(user_input: str, options: list, context: dict) -> str:
    """ä½¿ç”¨å°æ¨¡å‹è§£æè·¯çº¿é€‰æ‹©"""
    prompt = PromptTemplate(
        template="ä»ç”¨æˆ·è¾“å…¥è§£æè·¯çº¿é€‰æ‹©ï¼š\né€‰é¡¹åˆ—è¡¨ï¼š{options}\nç”¨æˆ·è¾“å…¥ï¼š{user_input}\nè¿”å›[è·¯çº¿åç§°ï¼šç‰¹è‰²æè¿°]",
        input_variables=["options", "user_input"]
    )
    chain = prompt | option_parser_llm | StrOutputParser()
    return chain.invoke({"options": options, "user_input": user_input})

def handle_route_selection_chain() -> RunnableSequence:
    """ä¸“ç”¨æ”»ç•¥ç”Ÿæˆé“¾"""
    llm = create_llm()
    GUIDE_PROMPT = PromptTemplate(
        input_variables=["preference_info", "spot_info", "route_info"],
        template="""# æ·±åº¦æ—…æ¸¸æ”»ç•¥ç”Ÿæˆ
        
    ç”¨æˆ·éœ€æ±‚ï¼š{preference_info}
    é€‰å®šæ™¯ç‚¹ï¼š{spot_info}
    é€‰æ‹©è·¯çº¿ï¼š{route_info}

    è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼Œè¾“å‡ºæ’ç‰ˆå¥½çš„markdownï¼š
    ## è¡Œç¨‹å®‰æ’ï¼ˆç²¾ç¡®åˆ°å°æ—¶ï¼Œè¡¨æ ¼å½¢å¼ï¼‰
    ## å¿…ç©é¡¹ç›®ï¼ˆåŒ…å«æ¨èæ˜Ÿçº§ï¼‰
    ## é¤é¥®æ¨è
    ## é¢„ç®—ä¼°ç®—
    ## å®ç”¨è´´å£«"""
    )
    return (
        RunnablePassthrough()
        | GUIDE_PROMPT
        | llm.bind(stop=["\n\n"])
        | RunnableLambda(lambda x: x.content)
    )

def handle_route_selection(state: Dict, user_input: str) -> Generator[Dict, None, Dict]:
    """åŠ¨æ€ç”Ÿæˆæ”»ç•¥ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    # è§£æç”¨æˆ·é€‰æ‹©çš„æ™¯ç‚¹
    selected_route = route_selection_parse(
        user_input,
        state["options"],
        context=state["context"]
    )

    # ä½ å¥½
    chain = handle_route_selection_chain()
    result = chain.invoke({
        "preference_info": state["context"]["preference_info"],
        "spot_info": state["context"]["spot_info"],
        "route_info": selected_route
    })
    
    # æµå¼è¾“å‡ºå¤„ç†
    yield from format_streaming_response(render_markdown(result))
    return {
        **state,
        "step": TourismState.INIT,
        "context": {
            "preference_info": state["context"]["preference_info"],
            "spot_info": state["context"]["spot_info"],
            "route_info": selected_route,
            "timestamp": time.strftime("%Y-%m-%d %H:%M")
        }
    }

def handle_unknown(state: Dict, _: str) -> Generator[Dict, None, None]:
    """æœªçŸ¥çŠ¶æ€å¤„ç†"""
    yield from format_streaming_response("âš ï¸ ç³»ç»Ÿé‡åˆ°æœªçŸ¥çŠ¶æ€ï¼Œæ­£åœ¨é‡ç½®...")
    return {**state, "step": TourismState.INIT}

def test_llm_connection():
    """å¤§æ¨¡å‹è¿é€šæ€§æµ‹è¯•"""
    print("\n=== å¼€å§‹å¤§æ¨¡å‹è¿é€šæ€§æµ‹è¯• ===")
    try:
        llm = create_llm()
        test_prompt = PromptTemplate.from_template("è¯·è¯´ï¼š'æµ‹è¯•æˆåŠŸ'")
        chain = test_prompt | llm
        
        # å¸¦è¶…æ—¶çš„æµ‹è¯•è¯·æ±‚
        response = chain.invoke({"dummy": ""}).content
        if "æµ‹è¯•æˆåŠŸ" in response:
            print(f"âœ… å¤§æ¨¡å‹è¿æ¥æˆåŠŸï¼å“åº”å†…å®¹ï¼š{response}")
            return True
        else:
            print(f"âš ï¸ å¼‚å¸¸å“åº”ï¼š{response}")
            return False
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥ï¼š{str(e)}")
        print("å¯èƒ½åŸå› ï¼š")
        print("1. APIå¯†é’¥æ— æ•ˆ")
        print("2. ç½‘ç»œè¿æ¥å¼‚å¸¸")
        print("3. æ¨¡å‹æœåŠ¡ä¸å¯ç”¨")
        return False

# ---------- æ–°å¢æµ‹è¯•éªŒè¯å‡½æ•° ----------
def test_initialization() -> Dict:
    """æµ‹è¯•åˆå§‹åŒ–æµç¨‹"""
    print("\n=== æµ‹è¯•åˆå§‹åŒ– ===")
    state = {"step": TourismState.INIT}
    response_gen = state_machine(state, "")
    
    full_response = ""
    final_state = state
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                final_state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration:
        pass
    
    # éªŒè¯å…³é”®å­—æ®µ
    assert final_state["step"] == TourismState.GET_PREFERENCE, "åˆå§‹åŒ–ååº”è¿›å…¥åå¥½è·å–çŠ¶æ€"
    print("âœ… åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    return final_state

def test_preference_input(prev_state: Dict) -> Dict:
    """æµ‹è¯•åå¥½è¾“å…¥æµç¨‹"""
    print("\n=== æµ‹è¯•åå¥½è¾“å…¥ ===")
    user_input = "æˆ‘æƒ³çœ‹çš‡å®¶å›­æ—"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state  # åˆå§‹åŒ–çŠ¶æ€
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    # éªŒè¯é€‰é¡¹ç”Ÿæˆ
    assert len(state["options"]) >= 1, "åº”ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ™¯ç‚¹é€‰é¡¹"
    assert state["step"] == TourismState.SELECT_SPOT, "è¾“å…¥åå¥½ååº”è¿›å…¥æ™¯ç‚¹é€‰æ‹©çŠ¶æ€"
    print("âœ… åå¥½è¾“å…¥æµ‹è¯•é€šè¿‡")
    return state

def test_spot_selection(prev_state: Dict) -> Dict:
    """æµ‹è¯•æ™¯ç‚¹é€‰æ‹©æµç¨‹"""
    print("\n=== æµ‹è¯•æ™¯ç‚¹é€‰æ‹© ===")
    user_input = "é€‰ç¬¬ä¸€ä¸ªæ™¯ç‚¹"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    assert "selected_spot" in state, "åº”è®°å½•å·²é€‰æ™¯ç‚¹"
    assert len(state["options"]) >= 1, "åº”ç”Ÿæˆè‡³å°‘ä¸€ä¸ªè·¯çº¿é€‰é¡¹"
    print("âœ… æ™¯ç‚¹é€‰æ‹©æµ‹è¯•é€šè¿‡")
    return state

def test_route_selection(prev_state: Dict) -> Dict:
    """æµ‹è¯•è·¯çº¿é€‰æ‹©æµç¨‹"""
    print("\n=== æµ‹è¯•è·¯çº¿é€‰æ‹© ===")
    user_input = "é€‰æ–‡åŒ–è·¯çº¿"
    response_gen = state_machine(prev_state, user_input)
    
    full_response = ""
    state = prev_state  # å…³é”®ä¿®å¤ï¼šåˆå§‹åŒ–çŠ¶æ€
    try:
        for chunk in response_gen:
            if chunk.get("final_state"):
                state = chunk["final_state"]
                continue
            content = chunk['messages'][0]['content']
            print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
            full_response += content
        print("\n" + "-"*50)
    except StopIteration as e:
        state = e.value if isinstance(e.value, dict) else state
    
    # éªŒè¯æœ€ç»ˆçŠ¶æ€
    assert state["step"] == TourismState.INIT, "å®Œæˆæµç¨‹ååº”é‡ç½®çŠ¶æ€"
    assert "selected_route" in state, "åº”è®°å½•å·²é€‰è·¯çº¿"
    print("âœ… è·¯çº¿é€‰æ‹©æµ‹è¯•é€šè¿‡")
    return state

# ---------- æ–°å¢é“¾å¼çŠ¶æ€æœºå®ç° ----------
def new_state_machine(state: Dict, user_input: str) -> Generator[Dict, None, None]:
    """é“¾å¼çŠ¶æ€æœºï¼ˆæ–°å¢å®ç°ï¼‰"""
    processing_chain = (
        RunnablePassthrough.assign(
            # é¢„å¤„ç†ç”¨æˆ·è¾“å…¥
            processed_input=lambda x: x["user_input"].strip()
        )
        | build_state_chain()
        | RunnableAssign({
            "final_output": lambda x: x["messages"][-1]["content"]
        })
    )
    
    try:
        # æ‰§è¡Œå¤„ç†é“¾
        result = processing_chain.invoke({
            **state,
            "user_input": user_input,
            "messages": []
        })
        
        # æµå¼è¾“å‡ºå¤„ç†
        yield from result["messages"]
        yield {"final_state": result}
        
    except Exception as e:
        yield from format_streaming_response(f"âš ï¸ å¤„ç†å¼‚å¸¸ï¼š{str(e)}")
        yield {"final_state": state}


# æ–°å¢äº¤äº’æ¼”ç¤ºå‡½æ•°
def interactive_demo_with_chain():
    """å‘½ä»¤è¡Œäº¤äº’æ¼”ç¤º"""
    print("ğŸ›« æ—…æ¸¸åŠ©æ‰‹ æ§åˆ¶å°äº¤äº’æ¨¡å¼ï¼ˆè¾“å…¥exité€€å‡ºï¼‰")
    state = {"step": TourismState.INIT}
    
    while True:
        try:
            # æ ¹æ®çŠ¶æ€æç¤ºè¾“å…¥
            if state["step"] == TourismState.INIT:
                user_input = input("\n> æŒ‰å›è½¦å¼€å§‹è§„åˆ’æ—…ç¨‹ï¼š") or ""
            elif state["step"] == TourismState.GET_PREFERENCE:
                user_input = input("\n> è¯·æè¿°æ‚¨çš„æ—…æ¸¸åå¥½ï¼ˆå¦‚ï¼šæƒ³çœ‹çš‡å®¶å»ºç­‘ï¼‰ï¼š")
            elif state["step"] == TourismState.SELECT_SPOT:
                print("\næ¨èæ™¯ç‚¹ï¼š")
                for i, spot in enumerate(state.get("options", []), 1):
                    print(f"  {i}. {spot}")
                user_input = input("> è¯·é€‰æ‹©æ™¯ç‚¹ç¼–å·æˆ–åç§°ï¼š")
            elif state["step"] == TourismState.SELECT_ROUTE:
                print("\næ¨èè·¯çº¿ï¼š")
                for i, route in enumerate(state.get("options", []), 1):
                    print(f"  {i}. {route}")
                user_input = input("> è¯·é€‰æ‹©è·¯çº¿ç¼–å·æˆ–åç§°ï¼š")
            
            if user_input.lower() == "exit":
                break

            # è·å–å“åº”ç”Ÿæˆå™¨
            response_gen = new_state_machine(state, user_input)
            
            # å¤„ç†å“åº”æµ
            full_response = ""
            for chunk in response_gen:
                if chunk.get("final_state"):
                    # å…³é”®ä¿®å¤ï¼šæ›´æ–°çŠ¶æ€
                    state = chunk["final_state"]
                    continue
                if chunk.get("messages"):
                    content = chunk['messages'][0]['content']
                    print(f"\rç³»ç»Ÿï¼š{full_response}{content}", end="", flush=True)
                    full_response += content
            
            # çŠ¶æ€ç»“æŸå¤„ç†
            if state["step"] == TourismState.INIT and "context" in state:
                print("\n\nâœ… è¡Œç¨‹è§„åˆ’å®Œæˆï¼")
                print("-"*50)
                if state["context"].get("route_info"):
                    print(state["context"]["route_info"])
                print("-"*50)
                state = {"step": TourismState.INIT}  # é‡ç½®çŠ¶æ€

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break

# æ—§çš„çŠ¶æ€æœºå‡½æ•°ï¼Œä¿ç•™ç”¨äºéªŒè¯ã€‚
def interactive_demo():
    """å‘½ä»¤è¡Œäº¤äº’æ¼”ç¤º"""
    print("ğŸ›« æ—…æ¸¸åŠ©æ‰‹ æ§åˆ¶å°äº¤äº’æ¨¡å¼ï¼ˆè¾“å…¥exité€€å‡ºï¼‰")
    state = {"step": TourismState.INIT}
    
    while True:
        try:
            # æ ¹æ®çŠ¶æ€æç¤ºè¾“å…¥
            if state["step"] == TourismState.INIT:
                user_input = input("\n> æŒ‰å›è½¦å¼€å§‹è§„åˆ’æ—…ç¨‹ï¼š") or ""
            elif state["step"] == TourismState.GET_PREFERENCE:
                user_input = input("\n> è¯·æè¿°æ‚¨çš„æ—…æ¸¸åå¥½ï¼ˆå¦‚ï¼šæƒ³çœ‹çš‡å®¶å»ºç­‘ï¼‰ï¼š")
            elif state["step"] == TourismState.SELECT_SPOT:
                print("\næ¨èæ™¯ç‚¹ï¼š")
                for i, spot in enumerate(state["options"], 1):
                    print(f"  {i}. {spot}")
                user_input = input("> è¯·é€‰æ‹©æ™¯ç‚¹ç¼–å·æˆ–åç§°ï¼š")
            elif state["step"] == TourismState.SELECT_ROUTE:
                print("\næ¨èè·¯çº¿ï¼š")
                for i, route in enumerate(state["options"], 1):
                    print(f"  {i}. {route}")
                user_input = input("> è¯·é€‰æ‹©è·¯çº¿ç¼–å·æˆ–åç§°ï¼š")
            
            if user_input.lower() == "exit":
                break

            # ä¿®æ”¹è°ƒç”¨ç‚¹ä¸ºæ–°çŠ¶æ€æœº
            response_gen = new_state_machine(state, user_input)  # æ”¹ä¸ºè°ƒç”¨æ–°çŠ¶æ€æœº
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            if state["step"] == TourismState.INIT and "selected_route" in state:
                print("\n\nâœ… è¡Œç¨‹è§„åˆ’å®Œæˆï¼")
                print("-"*50)
                print(response_gen.send(None))
                print("-"*50)
                state = {"step": TourismState.INIT}  # é‡ç½®çŠ¶æ€

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break

# ---------- æ›´æ–°ä¸»æµç¨‹ ----------
if __name__ == "__main__":
    print("å¼€å§‹å’¯~")
    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = create_llm()
    print("âœ… å¤§æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    
    # å¯åŠ¨äº¤äº’æ¨¡å¼
    interactive_demo_with_chain()
    # interactive_demo() #æ—§çŠ¶æ€æœºå‡½æ•°

